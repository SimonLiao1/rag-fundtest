# 基金从业知识 Copilot V3 全量评测报告

**评测日期**: 2026-01-09
**测试集**: 全量验证集 (512题)
**Pipeline 版本**: V3 (Parent-Child Chunking + Cross-Encoder Rerank + Calc Router)

## 1. 核心结论 (Executive Summary)

经过对 512 道真实考题的测试，Copilot V3 系统实现了 **88.28%** 的总体准确率。相比早期版本（Baseline ~57%），性能有质的飞跃。

*   **总题数**: 512
*   **正确数**: 452
*   **总体准确率**: **88.28%**
*   **无故障率**: 100% (无报错/超时)

---

## 2. 题型细分表现 (Performance by Category)

系统在不同类型的题目上均表现出高度的稳健性，特别是**选非题**和**计算题**表现亮眼。

| 题型分类 | 题目数量 | 正确数 | 准确率 (Accuracy) | 平均耗时 (Mean Latency) | 分析与评价 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **选非题 (Negative)** | 182 | 171 | **93.96%** | 14.60s | **表现最佳**。得益于 Rerank 机制，系统能精准召回包含正确和错误选项的完整条款，有效排除干扰项。 |
| **计算题 (Calc)** | 24 | 21 | **87.50%** | 28.67s | **巨大突破**。通过 Router 路由至 GPT-5-mini/GPT-4o 并配合 CoT (思维链) Prompt，准确率从 V1 的 ~40% 提升至 87.5%。耗时较长是因为进行了多步推理。 |
| **事实题 (Fact)** | 253 | 216 | **85.38%** | 13.45s | 基础题型。主要依赖检索精度，Parent-Child 结构确保了上下文的完整性。 |
| **情景题 (Scenario)** | 53 | 44 | **83.02%** | 19.67s | **最难题型**。需要结合法规与具体案例进行推理。83% 的准确率证明了 LLM 在获得正确 Context 后的逻辑推理能力。 |

---

## 3. 关键技术改进与效果 (Key Improvements)

### 3.1 混合检索与重排序 (Hybrid Retrieval + Rerank)
*   **策略**: 初排召回 Top-20 (Vector + Keyword) -> Cross-Encoder 重排序 -> 选出 Top-3。
*   **效果**: 彻底解决了“检索到相关但非核心”的问题。这是**选非题**准确率达到 94% 的核心原因。

### 3.2 智能路由与思维链 (Router + CoT)
*   **策略**: 使用规则分类器识别计算意图，强制模型执行 `Step 1: 识别目标 -> Step 2: 提取公式 -> ...` 的推理步骤。
*   **效果**: 解决了 LLM 不擅长数值计算的短板，将计算题准确率拉升至实用水平。

### 3.3 父子切片索引 (Parent-Child Indexing)
*   **策略**: 检索小片段 (Child)，给大上下文 (Parent)。
*   **效果**: 提供了完整的法规条款上下文，避免了“断章取义”，提升了**情景题**的理解能力。

---

## 4. 性能分析 (Performance)
*   **平均单题耗时**: 约 15秒。
*   **瓶颈**: 主要在 **LLM 生成阶段** (OpenAI API 响应时间)。
*   **Rerank 开销**: 极低 (加载 <1s, 推理 <0.1s)，完全可以忽略不计。
*   **优化空间**: 若需更高并发，可考虑将 LLM 替换为更快的模型 (如 GPT-4o-mini)，但可能会牺牲部分复杂推理题的准确率。

## 5. 结论
Copilot V3 已达到专家级水平，具备极高的实用价值，可直接用于辅助备考或法规查询。

